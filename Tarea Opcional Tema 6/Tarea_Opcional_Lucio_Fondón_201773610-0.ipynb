{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "892ql0YMm1C4"
   },
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-280 Estadística Computacional I-2020 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea Voluntaria Tema 6 - El Quijote y La Verosimilitud  </H3>\n",
    "<H3 align='center'> Nombre: Lucio Fondón Rebolledo </H3>\n",
    "<H3 align='center'> Rol: 201773610-0 </H3>\n",
    "<H3 align='center'> Paralelo: 201 </H3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wEUeIcy6m6Cv"
   },
   "source": [
    "En esta tarea debe utilizar el método de máxima verosimilitud para desencriptar el mensaje de más abajo:\n",
    "\n",
    "\n",
    "**iublzlvdu vyf lzyccmqdu lhl it hylcitbitl gicd lñdcl yt gdhd vixdc ñlhmitqd iubl blcil dghmdtlp qi iublqmubmhl hdvgyblhmdtlp**\n",
    "\n",
    "\n",
    "Los materiales de los dispondrá, corresponden a las probabilidades de aparición\n",
    "de las 29 letras del alfabeto español, calculadas desde libro \"El Ingenioso Hidalgo don Quijote de la Mancha\", una de los libros más leídos en el mundo. Los datos estarán disponibles en un archivo denominado 'freq_esp.csv' que se puede cargar con el código entregado más abajo.\n",
    "\n",
    "\n",
    "El texto que debe decifrar no contiene ni acentos ni signos de puntuación, sólo letras y espacios. Estos últimos han sido mantenidos en la encriptación. Se sabe además que el algoritmo de encriptación es muy sencillo y funciona sustituyendo una letra del alfabeto por otra. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qbXuJ8ay27pL"
   },
   "source": [
    "## **Decriptación de Máxima Verosimilitud**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 'a', 'o', 's', 'n', 'r', 'i', 'l', 'd', 'u', 't', 'c', 'm', 'p', 'q', 'y', 'b', 'h', 'v', 'g', 'j', 'f', 'z', 'ñ', 'k', 'w', 'x']\n",
      "[0.14 0.12 0.1  0.08 0.07 0.06 0.05 0.05 0.05 0.05 0.04 0.04 0.03 0.02\n",
      " 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.01 0.   0.   0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "cripted_text = 'iublzlvdu vyf lzyccmqdu lhl it hylcitbitl gicd yt gdhd vixdc lñdcl jyi iubyqmlvdu iublqmubmhl'\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "quijote = pd.read_csv('freq_esp.csv',sep='\\t',names=[\"letra\",\"ocurrencia\", \"probabilidad\"])  \n",
    "quijote['probabilidad'] = quijote['probabilidad']+0.1\n",
    "quijote['probabilidad'] = quijote['probabilidad']/np.sum(quijote['probabilidad'].values)\n",
    "\n",
    "n_letras = len(quijote['letra'].values)\n",
    "\n",
    "#ejemplo de como extraer la probabilidad de la letra ñ desde el dataframe\n",
    "value = quijote.loc[quijote['letra'] == 'ñ']['probabilidad']\n",
    "\n",
    "#si les acomoda mas trabajar con arrreglos en vez de dataframes, aca se extraen\n",
    "letras = quijote['letra'].values\n",
    "probabilidades = quijote['probabilidad'].values\n",
    "\n",
    "letras = letras.tolist()\n",
    "\n",
    "print(letras)\n",
    "print(np.round(probabilidades,2))\n",
    "# plt.plot(letras, probabilidades)\n",
    "# plt.ylabel(\"Probabilidades\")\n",
    "# plt.xlabel(\"Letras\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoejJ9cIoDqt"
   },
   "source": [
    "Se le da como dato que  la llave de sustitución consiste en correr de manera cíclica el alfabeto (ordenado por frecuencia) de $\\delta$ unidades hacia la derecha. \n",
    "\n",
    "['e' 'a' 'o' 's' 'n' 'r' 'i' 'l' 'd' 'u' 't' 'c' 'm' 'p' 'q' 'y' 'b' 'h'\n",
    " 'v' 'g' 'j' 'f' 'z' 'ñ' 'k' 'w' 'x']\n",
    "\n",
    "Por ejemplo, si $\\delta=3$, la 'e' se cambiaría por una 's', la 'b' por 'g', la 'c' por 'q', la 'x' por una 'o', etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Desarrollo**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que nos han entregado ya las probabilidades de que salga cada letra, por lo tanto, ya tenemos la función de probabilidad asociada al problema, lo que implica que no debemos estimar alguna distribución de probabilidad adecuada, entonces, podemos aplicar directamente la funcion de verosimilutud con la función dada anteriormente, utilizando un parámetro $\\theta$, el cual será el $\\delta$ que es la llave de sustitución de $\\delta$ unidades a la derecha. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, sabemos que la función de verosimilitud está dada por:\n",
    "\n",
    "\\begin{align*}\n",
    "L(\\theta) = P(S|\\theta) = \\prod_{i=1}^n f(x_i;\\theta)   \\  .\n",
    "\\end{align*}\n",
    "\n",
    "En donde $f(x;\\theta)$ es la función de distribución de probabilidades de la aparición de las letras dado un $\\theta$.\n",
    "\n",
    "Como sabemos, la pitatoria de probabilidades tiende a trabajar con números que son exageradamente pequeños, por lo que se procederá a sacar la máxima verosimilitud con la función de log-verosimilitud, la cual está dada por:\n",
    "\n",
    "\\begin{align*}\n",
    "\\ln (L(\\theta)) = \\ell(\\theta) = \\ln P(S|\\theta) = \\sum_{i=1}^n \\ln f(x_i;\\theta)   \\  .\n",
    "\\end{align*}\n",
    "\n",
    "El siguiente extracto de código pasa las probabilidades a sus respectivos logaritmos, en donde retorna un diccionario con las letras y su probabilidad con el logaritmo aplicado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': -1.9868050892432363,\n",
       " 'a': -2.1233806242489868,\n",
       " 'o': -2.330394793633313,\n",
       " 's': -2.5788561529318126,\n",
       " 'n': -2.7308723602304386,\n",
       " 'r': -2.7924302532298717,\n",
       " 'i': -2.910213288886255,\n",
       " 'l': -2.9282317943889336,\n",
       " 'd': -2.94658093305713,\n",
       " 'u': -3.043744681510778,\n",
       " 't': -3.272003333491758,\n",
       " 'c': -3.32464706697718,\n",
       " 'm': -3.6033604694462005,\n",
       " 'p': -3.8000707636922546,\n",
       " 'q': -3.8910425418979813,\n",
       " 'y': -4.162976257381623,\n",
       " 'b': -4.162976257381623,\n",
       " 'h': -4.3706156221598675,\n",
       " 'v': -4.450658329833404,\n",
       " 'g': -4.537669706823034,\n",
       " 'j': -4.989654830566091,\n",
       " 'f': -5.143805510393349,\n",
       " 'z': -5.326127067187304,\n",
       " 'ñ': -5.549270618501514,\n",
       " 'k': -6.242417799061459,\n",
       " 'w': -6.840254799817079,\n",
       " 'x': -6.840254799817079}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilidades_log = {}\n",
    "for i in range(len(letras)):\n",
    "    probabilidades_log[letras[i]] = np.log(probabilidades[i])\n",
    "probabilidades_log    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, sabemos que los posibles candidatos de llaves de sustitución son la cantidad de letras del alfabeto, es decir, existen 27 posibilidades de llaves de sustitución, en este caso, yendo de 0 a 26 espacios corridos hacia la derecha, por lo tanto, se calculará la función de log-verosimilitud para cada uno de los textos posibles que generen los $\\theta$ candidatos, para luego poder verificar cuál de estos $\\theta$'s es el que entrega un mayor valor para la verosimilitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente codigo es una función realiza una sustitución cíclica de $\\theta$ espacios hacia la derecha dado un texto (string) como parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sustitucion(texto,theta):\n",
    "    uncripted_text = \"\"\n",
    "    texto = texto.split(\" \")\n",
    "    for palabra in texto:\n",
    "        nueva_palabra = \"\"\n",
    "        for letra in palabra:\n",
    "            indice_letra = letras.index(letra)\n",
    "            letra_sustituida = letras[(indice_letra + theta)%27]\n",
    "            nueva_palabra += letra_sustituida\n",
    "        uncripted_text += nueva_palabra\n",
    "        uncripted_text += \" \"\n",
    "    return uncripted_text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, realizaremos una función para poder calcular la log-verosimilitud de un texto dado. El siguiente código realiza esta función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_log_verosimilitud(texto):\n",
    "    suma = 0\n",
    "    for letra in texto:\n",
    "        if letra != \" \":\n",
    "            suma += probabilidades_log[letra]\n",
    "    return suma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, teniendo ambas dos funciones anteriores para trabajar, solo debemos encontrar el $\\theta$ que genera la mayor verosimilitud. Para esto, se utilizará la función anterior $\\verb|func_log_verosimilitud(texto)|$ para cada texto generado por $\\verb|sustitucion(texto,theta)|$, entonces:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El theta con mayor verosimilitud es de: 21\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "thetas_candidatos = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]\n",
    "log_verosimilitud_mayor = -math.inf\n",
    "theta_mvm = 0\n",
    "\n",
    "for theta in thetas_candidatos:\n",
    "    log_verosimilitud = func_log_verosimilitud(sustitucion(cripted_text,theta))\n",
    "    if log_verosimilitud > log_verosimilitud_mayor:\n",
    "        log_verosimilitud_mayor = log_verosimilitud\n",
    "        theta_mvm = theta\n",
    "print(\"El theta con mayor verosimilitud es de: \" + str(theta_mvm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que, según las funciones, hemos encontrado que el $\\theta$ de mayor verosimiltud es $\\theta = 21$ (desencriptando cíclicamente hacia la derecha), sólo nos resta probar en la función $\\verb|sustitucion(texto,theta)|$, con el parámetro $\\verb|theta = 21|$ para ver si efectivamente, encontramos el texto desencriptado (que se pueda leer y tenga coherencia es una buena señal de que estamos en lo correcto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estabamos muy aburridos aca en cuarentena pero un poco mejor ahora que estudiamos estadistica \n"
     ]
    }
   ],
   "source": [
    "texto_final = sustitucion(cripted_text,theta_mvm)\n",
    "print(texto_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y claramente, éste es el texto que desencriptado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Link video explicativo** : https://drive.google.com/file/d/1W5QJbpNvGDX_cmkLiIJZigzg9A3cb7H7/view?usp=sharing"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tarea-Opcional-ML",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
